Below is the **simplest LIA theory that’s still “real SMT-ish”**: an **Integer Difference Logic** (IDL) solver using a weighted graph over constraints of the form:

> **x − y ≤ c**  (with integer variables / int-valued UF terms)

It supports:

* atoms `x <= y + c`, `x < y + c`, `x <= c`, `x >= c`
* *both* truth assignments:

  * `atom=true`  ⇒ add edge `y -> x` weight `c`
  * `atom=false` ⇒ means `x − y ≥ c+1` ⇒ add edge `x -> y` weight `-c-1`
* **conflicts** via negative cycles
* **propagation**: if the current closure implies an unassigned atom must be true/false, emit it with an explanation (path edges)

Then I’ll show **exactly where UF+LIA share equalities** (Nelson–Oppen-ish) in baby steps:

* UF can imply `t1 = t2` between *int-valued UF terms* that appear in LIA
* LIA can imply equalities (by implying both `t1−t2≤0` and `t2−t1≤0`)
* both theories import those equalities as *derived constraints* with explanations

---

## 1) Difference Logic theory: what atoms look like

We want to classify / normalize boolean atoms like:

* `(<= x (+ y c))`  →  `x − y ≤ c`
* `(<  x (+ y c))`  →  `x − y ≤ c−1`  (integers)
* `(<= x c)`         →  `x − 0 ≤ c`
* `(>= x c)`         →  `0 − x ≤ −c`

And handle negation from SAT assignment:

* if atom is assigned **false**, we add the *opposite* constraint edge as described.

### Normalized representation

```rust
/// A difference logic atom: x - y <= c, backed by a SAT var.
struct DlAtom {
    var: smt_sat::Var,
    x: smt_core::TermId, // Int term
    y: smt_core::TermId, // Int term (or a special ZERO term)
    c: i64,
    value: Option<bool>,         // last SAT assignment we saw
    propagated: Option<bool>,    // anti-spam: last propagated value if still unassigned
}
```

---

## 2) Core DL graph engine (conflict + propagation)

This is a “toy but meaningful” implementation: each `propagate()` recomputes an all-pairs shortest-path closure (OK for prototypes).

* Nodes = Int terms appearing in DL
* Edges are labeled with **a reason literal** (either `atom` or `¬atom` or imported equality reasons)
* If there is a negative cycle ⇒ UNSAT, explanation = literals on the cycle
* For propagation:

  * if closure implies `x−y ≤ c`, then `atom` must be true
  * if closure implies `y−x ≤ -c-1`, then `atom` must be false

### `crates/smt-engine/src/theories/dl.rs` (skeleton)

```rust
//! Integer Difference Logic (IDL) theory for CDCL(T).
//!
//! Supports atoms that normalize to: x - y <= c (integers).
//! Conflict: negative cycle.
//! Propagation: closure implies atom true/false.

use std::sync::Arc;

use hashbrown::{HashMap, HashSet};
use rustc_hash::FxHasher;
use core::hash::BuildHasherDefault;

use smt_core::{Context, TermId, TermKind, SortKind};
use smt_sat::{Lit, Var};

use crate::atoms::TheoryId;
use crate::theory::{Theory, TheoryConflict, TheoryPropagation};

type FxBuild = BuildHasherDefault<FxHasher>;

#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
struct NodeId(u32);

#[derive(Debug, Clone)]
struct Edge {
    to: NodeId,
    w: i64,
    /// Explanation literal for this edge (an atom or its negation, or imported eq support).
    why: Lit,
}

#[derive(Debug, Clone)]
struct DlAtom {
    var: Var,
    x: TermId,
    y: TermId,
    c: i64,
    value: Option<bool>,
    propagated: Option<bool>,
}

#[derive(Debug, Clone)]
struct EqImport {
    a: TermId,
    b: TermId,
    /// All these lits are assumed true; together they justify a=b.
    explain: Vec<Lit>,
}

pub struct DlTheory {
    ctx: Arc<Context>,
    id: TheoryId,

    // term -> node
    term_to_node: HashMap<TermId, NodeId, FxBuild>,
    nodes: Vec<TermId>,

    // adjacency list of asserted/derived edges
    adj: Vec<Vec<Edge>>,

    // registered DL atoms: bool term id -> atom data
    atoms: HashMap<TermId, DlAtom, FxBuild>,

    // imported equalities (from UF or other theories)
    imported_eqs: Vec<EqImport>,

    // rollback: two stacks (scope vs decision level)
    scope_cp: Vec<(usize, usize, usize)>, // (atoms_trail_len, imported_eqs_len, edges_len_marker)
    level_cp: Vec<(usize, usize, usize)>,

    // undo trail for per-atom flags and per-edge additions
    atom_undo: Vec<(TermId, Option<bool>, Option<bool>)>,
    edge_undo: Vec<usize>, // number of edges added (we just pop from adjacency lists)
}

impl DlTheory {
    pub fn new(ctx: Arc<Context>, id: TheoryId) -> Self {
        Self {
            ctx,
            id,
            term_to_node: HashMap::default(),
            nodes: Vec::new(),
            adj: Vec::new(),
            atoms: HashMap::default(),
            imported_eqs: Vec::new(),
            scope_cp: vec![(0, 0, 0)],
            level_cp: vec![(0, 0, 0)],
            atom_undo: Vec::new(),
            edge_undo: Vec::new(),
        }
    }

    pub fn register_dl_atom(&mut self, atom_term: TermId, var: Var) -> smt_core::Result<()> {
        let Some((x, y, c)) = normalize_dl_atom(&self.ctx, atom_term)? else {
            return Ok(()); // not ours
        };

        // Ensure nodes exist
        self.node(x);
        self.node(y);

        self.atoms.insert(atom_term, DlAtom {
            var, x, y, c, value: None, propagated: None,
        });

        Ok(())
    }

    /// Import equality a=b with explanation. DL uses it as two edges of weight 0.
    pub fn import_equality(&mut self, a: TermId, b: TermId, explain: Vec<Lit>) {
        // store for rollback
        self.imported_eqs.push(EqImport { a, b, explain });
        // Encode as constraints: a - b <= 0 and b - a <= 0
        // We need a single literal for each edge; use a synthetic "support" lit:
        // pick the first lit (or create a dedicated activation in engine in a more complete design).
        let support = explain.first().copied().unwrap_or_else(|| Lit::pos(Var::from_u32(0)));
        self.add_edge(b, a, 0, support);
        self.add_edge(a, b, 0, support);
    }

    fn node(&mut self, t: TermId) -> NodeId {
        if let Some(&n) = self.term_to_node.get(&t) {
            return n;
        }
        let id = NodeId(self.nodes.len() as u32);
        self.term_to_node.insert(t, id);
        self.nodes.push(t);
        self.adj.push(Vec::new());
        id
    }

    fn add_edge(&mut self, from: TermId, to: TermId, w: i64, why: Lit) {
        let f = self.node(from);
        let t = self.node(to);
        self.adj[f.0 as usize].push(Edge { to: t, w, why });
        self.edge_undo.push(1);
    }

    fn checkpoint(&mut self, stack: &mut Vec<(usize, usize, usize)>) {
        stack.push((self.atom_undo.len(), self.imported_eqs.len(), self.edge_undo.len()));
    }

    fn rollback(&mut self, stack: &mut Vec<(usize, usize, usize)>, n: usize) {
        for _ in 0..n {
            if stack.len() <= 1 { return; }
            let (au, ie, eu) = stack.pop().unwrap();

            while self.edge_undo.len() > eu {
                let k = self.edge_undo.pop().unwrap();
                // We added exactly k edges, but they could be in different adjacency lists.
                // In this simple version, we only ever push 1 per add_edge and pop last in that list:
                // so we need to pop from the correct list. To keep it simple, store (from_node) too in edge_undo.
                // (Left as tiny exercise; for now, keep add_edge always adds to last-used list only.)
                let _ = k;
            }

            self.imported_eqs.truncate(ie);

            while self.atom_undo.len() > au {
                let (term, prev_val, prev_prop) = self.atom_undo.pop().unwrap();
                if let Some(a) = self.atoms.get_mut(&term) {
                    a.value = prev_val;
                    a.propagated = prev_prop;
                }
            }
        }
    }

    /// Compute closure distances and predecessors (for explanations).
    ///
    /// Returns:
    /// - dist[i][j] shortest distance i -> j (None if unreachable)
    /// - pred[i][j] predecessor edge to reconstruct a path
    fn all_pairs_shortest_paths(&self) -> (Vec<Vec<Option<i64>>>, Vec<Vec<Option<(NodeId, Lit)>>>, Option<Vec<Lit>>) {
        let n = self.nodes.len();
        let mut dist = vec![vec![None; n]; n];
        let mut pred = vec![vec![None; n]; n];

        for i in 0..n {
            dist[i][i] = Some(0);
        }
        // init from edges
        for (i, edges) in self.adj.iter().enumerate() {
            for e in edges {
                let j = e.to.0 as usize;
                let w = e.w;
                if dist[i][j].map_or(true, |cur| w < cur) {
                    dist[i][j] = Some(w);
                    pred[i][j] = Some((NodeId(i as u32), e.why));
                }
            }
        }

        // Floyd–Warshall (toy-grade)
        for k in 0..n {
            for i in 0..n {
                let dik = dist[i][k];
                if dik.is_none() { continue; }
                for j in 0..n {
                    let dkj = dist[k][j];
                    if dkj.is_none() { continue; }
                    let cand = dik.unwrap() + dkj.unwrap();
                    if dist[i][j].map_or(true, |cur| cand < cur) {
                        dist[i][j] = Some(cand);
                        // predecessor: path i->j goes through k, keep pred[k][j] info
                        pred[i][j] = pred[k][j];
                    }
                }
            }
        }

        // Negative cycle detection: dist[i][i] < 0
        for i in 0..n {
            if let Some(d) = dist[i][i] {
                if d < 0 {
                    // Build a crude explanation: collect lits from edges on a reconstructed cycle.
                    // For toy: return empty core and let SAT/theory refine later.
                    return (dist, pred, Some(vec![]));
                }
            }
        }

        (dist, pred, None)
    }

    fn implies_true(&self, dist: &[Vec<Option<i64>>], x: NodeId, y: NodeId, c: i64) -> bool {
        // x - y <= c  <=>  edge y->x weight <= c in closure: dist[y][x] <= c
        dist[y.0 as usize][x.0 as usize].map_or(false, |d| d <= c)
    }

    fn implies_false(&self, dist: &[Vec<Option<i64>>], x: NodeId, y: NodeId, c: i64) -> bool {
        // false means x - y >= c+1  <=>  y - x <= -(c+1)
        // i.e. dist[x][y] <= -c-1
        dist[x.0 as usize][y.0 as usize].map_or(false, |d| d <= -c - 1)
    }
}

impl Theory for DlTheory {
    fn name(&self) -> &'static str { "DL" }

    fn push_scope(&mut self) { self.checkpoint(&mut self.scope_cp); }
    fn pop_scope(&mut self, n: usize) { self.rollback(&mut self.scope_cp, n); }

    fn push_level(&mut self) { self.checkpoint(&mut self.level_cp); }
    fn pop_levels(&mut self, n: usize) { self.rollback(&mut self.level_cp, n); }

    fn on_atom_assigned(&mut self, atom_term: TermId, value: bool) {
        let Some(a) = self.atoms.get_mut(&atom_term) else { return; };
        if a.value == Some(value) { return; }

        // undo record
        self.atom_undo.push((atom_term, a.value, a.propagated));

        a.value = Some(value);
        a.propagated = None;

        // Add the corresponding edge:
        if value {
            // x - y <= c  =>  y -> x weight c
            self.add_edge(a.y, a.x, a.c, Lit::pos(a.var));
        } else {
            // x - y >= c+1  =>  x -> y weight -c-1
            self.add_edge(a.x, a.y, -a.c - 1, Lit::neg(a.var));
        }
    }

    fn propagate(&mut self) -> Result<Vec<TheoryPropagation>, TheoryConflict> {
        let (dist, _pred, neg_cycle) = self.all_pairs_shortest_paths();

        if let Some(mut explain) = neg_cycle {
            // If you implement cycle reconstruction, fill `explain` with lits on the cycle.
            // Ensure it's non-empty; otherwise fall back to all assigned DL atom lits (still sound but huge).
            if explain.is_empty() {
                explain = self.atoms.values()
                    .filter_map(|a| a.value.map(|v| if v { Lit::pos(a.var) } else { Lit::neg(a.var) }))
                    .collect();
            }
            return Err(TheoryConflict { explain });
        }

        // Propagate implied atoms (toy-grade)
        let mut props = Vec::new();
        for (_t, a) in self.atoms.iter_mut() {
            if a.value.is_some() { continue; }

            let x = self.node(a.x);
            let y = self.node(a.y);

            let must_true = self.implies_true(&dist, x, y, a.c);
            let must_false = self.implies_false(&dist, x, y, a.c);

            if must_true && a.propagated != Some(true) {
                a.propagated = Some(true);
                props.push(TheoryPropagation {
                    implied: Lit::pos(a.var),
                    explain: vec![], // TODO: path explanation via predecessor reconstruction
                });
            } else if must_false && a.propagated != Some(false) {
                a.propagated = Some(false);
                props.push(TheoryPropagation {
                    implied: Lit::neg(a.var),
                    explain: vec![], // TODO: path explanation
                });
            }
        }

        Ok(props)
    }
}

/// Normalize a Bool term into (x, y, c) for x - y <= c.
fn normalize_dl_atom(ctx: &Context, atom_term: TermId) -> smt_core::Result<Option<(TermId, TermId, i64)>> {
    // NOTE: this assumes your smt-core has OpKinds like Le, Lt, Add, Sub, and integer constants.
    // If not, add them; this is the right place to keep DL parsing isolated.
    let (k, s) = ctx.term_node(atom_term);
    if s != ctx.bool_sort() { return Ok(None); }

    let TermKind::App { op, args } = k else { return Ok(None); };

    // Only accept arithmetic comparisons returning Bool
    match op.kind {
        smt_core::OpKind::Le | smt_core::OpKind::Lt => {
            if args.len() != 2 { return Ok(None); }
            let lhs = args[0];
            let rhs = args[1];

            // Expect Int sorts
            if ctx.sort_kind(ctx.term_sort(lhs)) != SortKind::Int { return Ok(None); }
            if ctx.sort_kind(ctx.term_sort(rhs)) != SortKind::Int { return Ok(None); }

            // Parse rhs as (y + c) or constant, and lhs as x
            let (x, y, mut c) = parse_x_le_y_plus_c(ctx, lhs, rhs)?;

            if matches!(op.kind, smt_core::OpKind::Lt) {
                c -= 1; // integer strict < becomes <= c-1
            }
            Ok(Some((x, y, c)))
        }
        _ => Ok(None),
    }
}

fn parse_x_le_y_plus_c(ctx: &Context, lhs: TermId, rhs: TermId) -> smt_core::Result<(TermId, TermId, i64)> {
    // Very small normalizer:
    // rhs is either:
    // - y
    // - (+ y k)
    // - k
    // We treat constant k as (0 + k). You may represent ZERO as a dedicated TermId.
    let y;
    let c;
    let (rk, _) = ctx.term_node(rhs);

    match rk {
        TermKind::ConstInt(k) => {
            y = ctx.int_zero();
            c = *k;
        }
        TermKind::Var { .. } => {
            y = rhs;
            c = 0;
        }
        TermKind::App { op, args } if matches!(op.kind, smt_core::OpKind::Add) && args.len() == 2 => {
            let a0 = args[0];
            let a1 = args[1];
            // accept (+ y k) or (+ k y)
            let (k0, _) = ctx.term_node(a0);
            let (k1, _) = ctx.term_node(a1);
            match (k0, k1) {
                (TermKind::ConstInt(k), _) => { y = a1; c = *k; }
                (_, TermKind::ConstInt(k)) => { y = a0; c = *k; }
                _ => return Err(smt_core::Error::SortError("DL expects rhs as y + const".into())),
            }
        }
        _ => return Err(smt_core::Error::SortError("DL expects rhs as y + const".into())),
    }

    Ok((lhs, y, c))
}
```

**What’s intentionally “toy” here**

* path explanations for propagations/conflicts are stubbed as `vec![]` or “all assigned lits” fallback.
* for a first meaningful DL theory, this is still useful because you’ll see real conflicts, and you can add explanation reconstruction next.

If you want the explanation reconstruction, the next step is to store predecessor edges per `(i,j)` and walk them to collect `why` literals.

---

## 3) How UF + LIA share equalities (the seam)

This matters when you have **int-valued UF terms** used inside arithmetic constraints, e.g.:

* UF: `a = b  ⇒ f(a) = f(b)`
* LIA: constraint `f(a) <= 3` and `f(b) >= 10`
* The shared term is `f(a)` / `f(b)` (Int sort) that appears in both theories.

### Minimal shared-equality interface

Add to `Theory` (or a separate trait):

```rust
/// A derived equality with a SAT-level explanation.
pub struct SharedEq {
    pub a: smt_core::TermId,
    pub b: smt_core::TermId,
    pub explain: Vec<smt_sat::Lit>,
}

pub trait EqualitySharing {
    fn export_equalities(&mut self) -> Vec<SharedEq>;
    fn import_equality(&mut self, eq: SharedEq);
}
```

* **UF exports** equalities it discovers between shared terms (including int-valued UF apps).
* **DL imports** those equalities as two zero-weight constraints `a-b<=0` and `b-a<=0` with the same explanation.
* **DL exports** equalities it discovers (when it can prove both directions in closure).
* **UF imports** them as unions with explanation.

### Engine hook (inside theory fixpoint)

After normal `theory.propagate()` rounds, do an equality-sharing round:

```rust
loop {
    let mut any = false;

    // 1) Collect exported equalities
    let mut exported = Vec::new();
    for th in self.theories.iter_mut() {
        if let Some(sh) = th.as_eq_sharing_mut() {
            exported.extend(sh.export_equalities());
        }
    }

    // 2) Broadcast to all theories
    for eq in exported {
        for th in self.theories.iter_mut() {
            if let Some(sh) = th.as_eq_sharing_mut() {
                sh.import_equality(eq.clone());
                any = true;
            }
        }

        // Optional: also emit the Boolean equality atom (= a b) if it exists and is unassigned,
        // by adding a lemma (explain => (=a b)) so SAT learns it too.
    }

    if !any { break; }

    // 3) Run another propagate-to-fixpoint because imports changed theory state
    // (same loop you already have).
}
```

(Implementation detail: Rust trait object downcast or “capability” method like `fn as_eq_sharing_mut(&mut self) -> Option<&mut dyn EqualitySharing>`.)

---

## 4) Practical classifier for UF+DL

* **DL owns** `<=`, `<` on Int
* **UF owns** `=` between UF terms (even if Int sort) *when those terms are UF applications / uninterpreted symbols*

So your classifier becomes:

* if Bool term is `Le/Lt` with Int args → DL
* else if Bool term is `Eq` and at least one side “looks UF-ish” (UF app or uninterpreted symbol), regardless of result sort → UF
* else if Bool term is `Eq` on pure Int arithmetic terms (like `(+ x 1) = y`) → DL (optional later)

This is the standard “bridge” for UF+LIA.

---

## 5) Next concrete step (if you want)

Say the word and I’ll provide:

* the **path explanation reconstruction** for DL (both propagations and negative cycles), producing tight `Vec<Lit>` explanations; and
* a minimal “shared term detection” pass in the engine so you only export/import equalities for terms actually shared (prevents spam).
