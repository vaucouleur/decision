Here’s a compact, “real SMT solver” public API and the minimal internal structure to support:

* `push/pop`
* `assert`
* `check_sat`
* `get_unsat_core` (labels)
* incremental **propositionalization across many asserts** (single global term→var map, no re-Tseitin duplication)

I’ll keep it concrete and Rust-idiomatic.

---

# 1) Public API surface

### `crates/smt/src/lib.rs` (facade crate)

```rust
#![forbid(unsafe_code)]
#![warn(missing_docs)]

use std::sync::Arc;

use smt_core::{BoolTerm, Context, TermId};
use smt_engine::{SmtEngine, SolveResult, AtomClassifier};
use smt_sat::{ToyCdcl};

/// User-facing assertion label.
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Label(pub String);

/// Result of check_sat.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CheckSat {
    Sat,
    Unsat,
}

/// High-level SMT solver handle.
pub struct Solver {
    ctx: Arc<Context>,
    eng: SmtEngine<ToyCdcl>,

    // label map for unsat cores
    lit_to_label: hashbrown::HashMap<smt_sat::Lit, Label, core::hash::BuildHasherDefault<rustc_hash::FxHasher>>,
}

impl Solver {
    /// Create a solver with a shared context, a classifier, and pre-built theories.
    pub fn new(ctx: Arc<Context>, mut eng: SmtEngine<ToyCdcl>) -> Self {
        Self {
            ctx,
            eng,
            lit_to_label: Default::default(),
        }
    }

    /// SMT-LIB push.
    pub fn push(&mut self) {
        self.eng.push();
    }

    /// SMT-LIB pop.
    pub fn pop(&mut self, n: usize) {
        self.eng.pop(n);
    }

    /// Assert a boolean term in the current scope.
    ///
    /// If `label` is provided, it will appear in the UNSAT core.
    pub fn assert(&mut self, term: BoolTerm, label: Option<Label>, classifier: &dyn AtomClassifier) -> smt_core::Result<()> {
        let act = self.eng.assert_term_scoped_incremental(&self.ctx, term, classifier)?;
        if let Some(lab) = label {
            self.lit_to_label.insert(act, lab);
        }
        Ok(())
    }

    /// Check satisfiability.
    pub fn check_sat(&mut self) -> CheckSat {
        match self.eng.solve() {
            SolveResult::Sat => CheckSat::Sat,
            SolveResult::Unsat => CheckSat::Unsat,
        }
    }

    /// If the last check was UNSAT, return an UNSAT core of labels (subset).
    pub fn get_unsat_core(&self) -> Vec<Label> {
        let Some(core) = self.eng.last_unsat_core() else {
            return Vec::new();
        };

        let mut out = Vec::new();
        for &lit in core {
            if let Some(l) = self.lit_to_label.get(&lit) {
                out.push(l.clone());
            }
        }
        out
    }

    pub fn ctx(&self) -> &Context {
        &self.ctx
    }
}
```

The important bit is that `assert()` returns (internally) an **activation literal** tied to that assertion. The engine stores it and assumes it during `solve()`.

---

# 2) Engine API that `Solver` relies on

You already have `push/pop/solve`. We add:

* `assert_term_scoped_incremental(...) -> Lit` returns the **assertion activation literal** (positive)
* `last_unsat_core() -> Option<&[Lit]>` forwards SAT kernel core
* incremental propositionalization by maintaining a global `TermId -> Var` map and a “tseitin done” mark.

### `crates/smt-engine/src/engine.rs` (key pieces)

```rust
use hashbrown::HashMap;
use rustc_hash::FxHasher;
use core::hash::BuildHasherDefault;

use smt_core::{BoolTerm, Context, TermId, TermKind};
use smt_sat::{Clause, Lit, Var};
use smt_sat::kernel::SatKernel;

use crate::propositionalize::AtomClassifier;
use crate::atoms::{Atom, AtomTable};

type FxBuild = BuildHasherDefault<FxHasher>;

struct ScopeFrame {
    act_scope: Lit,
    asserts: Vec<Lit>, // assertion activations in this scope
}

pub struct SmtEngine<K: SatKernel> {
    sat: K,
    atoms: AtomTable,
    theories: Vec<Box<dyn crate::theory::Theory>>,

    scopes: Vec<ScopeFrame>,
    sat_level_seen: usize,

    // incremental propositionalization
    term_to_var: HashMap<TermId, Var, FxBuild>,
    encoded: hashbrown::HashSet<TermId, FxBuild>, // terms for which we already emitted defining CNF
}

impl<K: SatKernel> SmtEngine<K> {
    pub fn new(mut sat: K, atoms: AtomTable, theories: Vec<Box<dyn crate::theory::Theory>>) -> Self {
        let act0 = Lit::pos(sat.fresh_var());
        Self {
            sat,
            atoms,
            theories,
            scopes: vec![ScopeFrame { act_scope: act0, asserts: Vec::new() }],
            sat_level_seen: 0,
            term_to_var: HashMap::default(),
            encoded: hashbrown::HashSet::default(),
        }
    }

    pub fn push(&mut self) {
        for th in self.theories.iter_mut() {
            th.push_scope();
        }
        let act = Lit::pos(self.sat.fresh_var());
        self.scopes.push(ScopeFrame { act_scope: act, asserts: Vec::new() });
    }

    pub fn pop(&mut self, n: usize) {
        let n = n.min(self.scopes.len().saturating_sub(1));
        for _ in 0..n {
            self.scopes.pop();
        }
        for th in self.theories.iter_mut() {
            th.pop_scope(n);
        }
    }

    /// Return the last UNSAT core as activation literals (subset), if available.
    pub fn last_unsat_core(&self) -> Option<&[Lit]> {
        self.sat.last_unsat_core()
    }

    /// Incremental assertion: propositionalize `term` (only new subterms produce CNF),
    /// then create an assertion activation literal and add:
    ///   (¬act_scope ∨ ¬act_assert ∨ root)
    ///
    /// Returns `act_assert` (positive literal) so the caller can label it.
    pub fn assert_term_scoped_incremental(
        &mut self,
        ctx: &Context,
        term: BoolTerm,
        classifier: &dyn AtomClassifier,
    ) -> smt_core::Result<Lit> {
        let root = self.encode_bool_term_incremental(ctx, term, classifier)?;

        let scope = self.scopes.last_mut().unwrap();

        let act_assert = Lit::pos(self.sat.fresh_var());
        scope.asserts.push(act_assert);

        self.sat.add_clause(vec![scope.act_scope.not(), act_assert.not(), root]);
        Ok(act_assert)
    }

    /// Encode (Tseitin) a BoolTerm incrementally.
    ///
    /// Returns the SAT literal representing the BoolTerm.
    fn encode_bool_term_incremental(
        &mut self,
        ctx: &Context,
        term: BoolTerm,
        classifier: &dyn AtomClassifier,
    ) -> smt_core::Result<Lit> {
        let tid = term.id();

        // Allocate or get var for this Bool term.
        let v = *self.term_to_var.entry(tid).or_insert_with(|| self.sat.fresh_var());

        // If we've already emitted defining clauses for this term, just return its literal.
        if self.encoded.contains(&tid) {
            return Ok(Lit::pos(v));
        }

        // Mark as encoded early to avoid recursion cycles.
        self.encoded.insert(tid);

        // Determine if this Bool term is a theory atom.
        if let Some(th) = classifier.classify_bool_term(ctx, tid) {
            // Register in AtomTable for the engine notification path.
            self.atoms.insert(v, Atom { term: tid, theory: th });

            // No CNF defining clauses for atoms; their truth is decided by SAT.
            return Ok(Lit::pos(v));
        }

        // Otherwise, it's pure boolean structure we Tseitin-encode:
        let (k, s) = ctx.term_node(tid);
        debug_assert_eq!(s, ctx.bool_sort());

        match k {
            TermKind::Var { .. } => {
                // Pure Boolean variable: no defining clauses.
                Ok(Lit::pos(v))
            }

            TermKind::App { op, args } => {
                use smt_core::OpKind;

                match op.kind {
                    OpKind::Not => {
                        let a = BoolTerm::try_from(args[0])?;
                        let la = self.encode_bool_term_incremental(ctx, a, classifier)?;
                        // v <-> ¬a
                        self.sat.add_clause(vec![Lit::neg(v), la.not()]);
                        self.sat.add_clause(vec![Lit::pos(v), la]);
                        Ok(Lit::pos(v))
                    }
                    OpKind::And => {
                        let mut lits = Vec::new();
                        for &t in args.iter() {
                            let bt = BoolTerm::try_from(t)?;
                            lits.push(self.encode_bool_term_incremental(ctx, bt, classifier)?);
                        }
                        // v -> (a1 ∧ ... ∧ an): (¬v ∨ ai) for each i
                        for &li in &lits {
                            self.sat.add_clause(vec![Lit::neg(v), li]);
                        }
                        // (a1 ∧ ... ∧ an) -> v: (v ∨ ¬a1 ∨ ... ∨ ¬an)
                        let mut c = Vec::with_capacity(lits.len() + 1);
                        c.push(Lit::pos(v));
                        for &li in &lits {
                            c.push(li.not());
                        }
                        self.sat.add_clause(c);
                        Ok(Lit::pos(v))
                    }
                    OpKind::Or => {
                        let mut lits = Vec::new();
                        for &t in args.iter() {
                            let bt = BoolTerm::try_from(t)?;
                            lits.push(self.encode_bool_term_incremental(ctx, bt, classifier)?);
                        }
                        // v -> (a1 ∨ ... ∨ an): (¬v ∨ a1 ∨ ... ∨ an)
                        let mut c = Vec::with_capacity(lits.len() + 1);
                        c.push(Lit::neg(v));
                        c.extend_from_slice(&lits);
                        self.sat.add_clause(c);

                        // (a1 ∨ ... ∨ an) -> v: (v ∨ ¬ai) for each i
                        for &li in &lits {
                            self.sat.add_clause(vec![Lit::pos(v), li.not()]);
                        }
                        Ok(Lit::pos(v))
                    }

                    // Any other boolean op is treated as an atom leaf if classifier didn't claim it.
                    _ => Ok(Lit::pos(v)),
                }
            }

            _ => Ok(Lit::pos(v)),
        }
    }

    // solve() and CDCL(T) loop remain as in the previous message,
    // but when seeding assumptions you should call sat.enqueue_assumption(...)
    // with:
    // - all scope activations
    // - all assertion activations in active scopes
}
```

### Seeding assumptions in `solve()`

Collect:

```rust
let mut assumptions = Vec::new();
for s in &self.scopes {
    assumptions.push(s.act_scope);
    assumptions.extend_from_slice(&s.asserts);
}
```

Then:

```rust
self.new_decision_level();
for a in assumptions {
    if !self.sat.enqueue_assumption(a) {
        return SolveResult::Unsat;
    }
}
```

And ensure `ToyCdcl` extracts `last_unsat_core` as described previously.

---

# 3) Mapping core literals back to terms (assertions)

In the facade `Solver`, you already keep `lit_to_label`. If you want **terms** too:

* store `lit_to_term: HashMap<Lit, BoolTerm>`
* return `(Label, BoolTerm)` pairs in core.

In `assert(...)`, after you get `act_assert`, store both.

---

# 4) Why this incremental propositionalization is “correct enough”

This approach:

* assigns **one SAT var per Bool subterm** (`term_to_var`)
* emits Tseitin constraints **once** per boolean structure term (`encoded` set)
* reuses already-encoded subterms across multiple assertions

That matches how serious solvers do it (a global Boolean abstraction layer).

**Caveat (fine for now):**

* If you later support term rewriting/simplification, you’ll want canonicalization so logically equal terms reuse vars.
* For now, structural `TermId` uniqueness in your DAG is usually enough.

---

# 5) Minimal user experience

Now you can offer:

```rust
solver.push();
solver.assert(phi, Some(Label("A".into())), classifier)?;
solver.assert(psi, Some(Label("B".into())), classifier)?;
match solver.check_sat() {
  CheckSat::Sat => {}
  CheckSat::Unsat => {
    println!("core: {:?}", solver.get_unsat_core());
  }
}
solver.pop(1);
```

…and it behaves like an SMT solver.

---

If you want the next step: say **yes** and I’ll add:

* a compact **SMT-LIB-ish front-end** on top of `Context` (declare-sort, declare-fun, assert, check-sat, get-unsat-core),
* and the first “real” combination story: UF + LIA with a Nelson–Oppen style shared-equality interface.
