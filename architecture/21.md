Here’s the **precise, rollback-correct** way to handle atom assignments inside `UfTheoryInc`, without the “clear all atom states” hack.

The design is simple and standard:

* Keep a **trail of atom assignments** in the theory wrapper (separate from UF’s internal trail).
* On `push()`, record a checkpoint (trail length + diseq length).
* On `pop(n)`, undo assignments back to the checkpoint:

  * restore each atom’s previous `value` and `propagated_true` flag
  * undo disequalities list
* UF itself already rolls back via `UfCc::push/pop`.

This is deterministic, fast, and doesn’t require the engine to rebuild anything.

---

# Patch `UfTheoryInc` for exact rollback

## 1) Add an assignment undo record

In `uf_theory_inc.rs`, add:

```rust
#[derive(Debug, Clone)]
struct AtomUndo {
    atom_term: TermId,
    prev_value: Option<bool>,
    prev_propagated_true: bool,
}
```

## 2) Add a per-theory trail + checkpoint stack

In `UfTheoryInc` struct, replace the simplistic `checkpoints` with:

```rust
    // Atom assignment undo trail.
    atom_trail: Vec<AtomUndo>,

    // Checkpoints for push/pop:
    // - how many atom undo records existed
    // - how many diseqs existed
    checkpoints: Vec<(usize, usize)>, // (atom_trail_len, diseqs_len)
```

Initialize in `new()`:

```rust
            atom_trail: Vec::new(),
            checkpoints: vec![(0, 0)],
```

## 3) Implement push/pop precisely

Replace `push()` and `pop()` with:

```rust
    fn push(&mut self) {
        self.uf.push();
        self.checkpoints.push((self.atom_trail.len(), self.diseqs.len()));
    }

    fn pop(&mut self, n: usize) {
        for _ in 0..n {
            if self.checkpoints.len() <= 1 {
                return;
            }

            // Restore checkpoint
            let (trail_len, diseq_len) = self.checkpoints.pop().unwrap();

            // Roll back UF internal state first (either order is fine, but keep consistent).
            self.uf.pop(1);

            // Undo atom assignments/flags
            while self.atom_trail.len() > trail_len {
                let undo = self.atom_trail.pop().unwrap();
                if let Some(a) = self.atoms.get_mut(&undo.atom_term) {
                    a.value = undo.prev_value;
                    a.propagated_true = undo.prev_propagated_true;
                }
            }

            // Truncate disequalities
            self.diseqs.truncate(diseq_len);
        }
    }
```

## 4) Record undo before mutating atom state

Update `on_atom_assigned`:

```rust
    fn on_atom_assigned(&mut self, atom_term: TermId, value: bool) {
        let Some(atom) = self.atoms.get_mut(&atom_term) else { return };

        // If no change, ignore.
        if atom.value == Some(value) {
            return;
        }

        // Record previous state for rollback.
        self.atom_trail.push(AtomUndo {
            atom_term,
            prev_value: atom.value,
            prev_propagated_true: atom.propagated_true,
        });

        // Apply new state.
        atom.value = Some(value);

        // If SAT assigned it, we don't need to “remember” a previous propagation.
        // (This also prevents some re-propagation oddities after backtracking.)
        atom.propagated_true = false;

        if value {
            let lit = Lit::pos(atom.var);
            self.uf.assert_eq_atom(atom.lhs, atom.rhs, lit);
        } else {
            let lit = Lit::neg(atom.var);
            self.diseqs.push(Diseq {
                lhs: atom.lhs,
                rhs: atom.rhs,
                lit,
                active: true,
            });
        }
    }
```

That’s it: theory state is now perfectly incremental and rollback-safe.

---

# Why this is “the right” SMT shape

* SAT already backtracks; theories must backtrack *exactly* in sync.
* The engine’s job is just to **notify** theories of new assignments.
* The theory wrapper’s job is to make that notification **reversible**.

With this patch:

* repeated solve calls and push/pop sequences work
* you can keep lemmas guarded with activation literals, or not—both work
* no need to clear all atom values on pop (which causes unnecessary rework)

---

# One subtlety: SAT backjump and theory undo synchronization

Your engine notifies theories by consuming SAT’s `trail()` from `trail_head..end`. When SAT **backjumps**, its trail shrinks, and we already fixed the SAT side (`notify_head` clamping). That ensures:

* the engine will never attempt to notify theories with stale literals past the new trail end
* theories can safely maintain state incrementally

However, there’s still one more thing you’ll want soon:

### On SAT backjump, theories must undo assignments too.

You have two implementation styles:

## Style A (simple and common): engine “replays” from scratch after backjump

* whenever SAT backtracks below some level, engine calls theory `pop()` appropriately (hard because SAT’s internal backjump levels aren’t exposed)

## Style B (better): make theories purely “trail-driven”

* theories don’t rely on `push/pop` except for SMT scopes
* instead, the engine also notifies theories when SAT unassigns literals (like a reversible trail)
* this is how many solvers integrate: theory has its own trail matching SAT’s trail

**Given your current design**, the easiest robust approach is:

### Expose SAT decision-level boundaries and let the engine mirror them into theory

Add to `SatKernel`:

```rust
fn trail_lim(&self) -> &[usize];  // decision level boundaries
```

Then the engine can detect when SAT backjumps (trail length decreases below previous head) and call:

* `theory.pop(k)` for theory-internal decision-level stack (distinct from SMT push/pop)

But you already have `Theory::push/pop` used for SMT scopes, so you may want a second stack for *search backtrackingchtracking*:

* `Theory::push_level()` / `pop_levels(n)` (search levels)
* keep SMT scopes separate

That’s exactly what cvc5/z3 do internally: “user scopes” vs “search trail”.

---

# Best next step (practical)

If you say **yes**, I’ll show the clean split:

* `Theory` gets **two** rollback APIs:

  * `push_scope/pop_scope` (user `push/pop`)
  * `push_level/pop_level` (SAT decision levels)
* the engine mirrors SAT decision levels to `push_level/pop_level` automatically
* you keep activation literals only for user scopes (much less overhead)

This keeps the whole system correct even with SAT internal backjump/restarts.
