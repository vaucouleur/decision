Great — here’s a clean, production-style way to make **user-scoped assertions** incremental via **activation literals**, while keeping **theory lemmas permanent**, and (optionally) extracting an **UNSAT core over user assertions**.

I’ll give you:

1. the scope mechanism (activation literals per scope)
2. how `assert` works (adds a guarded clause)
3. how `solve()` works (assumes all active activations)
4. a practical UNSAT core extraction over activations (subset core)

---

# 1) Engine scope stack with activation literals

We maintain a scope stack like SMT-LIB:

* `push` creates a new scope frame
* `assert φ` in a scope becomes clause `(¬act_scope ∨ φ)` where `act_scope` is this scope’s activation literal
* `solve` assumes all currently-active `act_scope` literals are `true`

On `pop`, you just remove those activation literals from assumptions; clauses stay in SAT but become inactive.

### Data

```rust
struct ScopeFrame {
    act: Lit,        // activation literal for this scope
}
```

---

# 2) Engine API: push / pop / assert / solve

### `crates/smt-engine/src/engine.rs`

```rust
use smt_sat::kernel::{SatKernel, LBool};
use smt_sat::{Clause, Lit};

use crate::propositionalize::{propositionalize, AtomClassifier};
use crate::atoms::{AtomTable, TheoryId};
use crate::theory::{Theory, TheoryConflict, TheoryPropagation};
use crate::engine_ctx::{implication_clause, conflict_clause};

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SolveResult { Sat, Unsat }

#[derive(Debug, Clone)]
struct ScopeFrame {
    act: Lit,
}

/// Main SMT engine:
/// - user scopes via activation literals
/// - CDCL(T) via SAT kernel + theories
pub struct SmtEngine<K: SatKernel> {
    sat: K,
    atoms: AtomTable,
    theories: Vec<Box<dyn Theory>>,

    // user scopes
    scopes: Vec<ScopeFrame>,

    // search-level syncing
    sat_level_seen: usize,
}

impl<K: SatKernel> SmtEngine<K> {
    pub fn new(mut sat: K, atoms: AtomTable, theories: Vec<Box<dyn Theory>>) -> Self {
        // Create base scope activation literal.
        let act0 = Lit::pos(sat.fresh_var());
        let scopes = vec![ScopeFrame { act: act0 }];

        Self {
            sat,
            atoms,
            theories,
            scopes,
            sat_level_seen: 0,
        }
    }

    /// SMT-LIB push.
    pub fn push(&mut self) {
        for th in self.theories.iter_mut() {
            th.push_scope();
        }
        let act = Lit::pos(self.sat.fresh_var());
        self.scopes.push(ScopeFrame { act });
    }

    /// SMT-LIB pop.
    pub fn pop(&mut self, n: usize) {
        let n = n.min(self.scopes.len().saturating_sub(1));
        for _ in 0..n {
            self.scopes.pop();
        }
        for th in self.theories.iter_mut() {
            th.pop_scope(n);
        }

        // We do NOT remove any SAT clause. Scope is handled by assumptions.
        // SAT state should typically be at level 0 between calls; your top-level driver can ensure that.
    }

    /// Assert a CNF clause in the current user scope.
    ///
    /// If you’re asserting an arbitrary Bool term φ, you first propositionalize φ
    /// into CNF and then call assert_cnf on (root lit).
    pub fn assert_clause_scoped(&mut self, mut clause: Clause) {
        // Guard with scope activation: (¬act ∨ clause...)
        let act = self.scopes.last().unwrap().act;
        clause.push(act.not());
        self.sat.add_clause(clause);
    }

    /// Assert a single literal in scope: (¬act ∨ lit)
    pub fn assert_lit_scoped(&mut self, lit: Lit) {
        self.assert_clause_scoped(vec![lit]);
    }

    /// Assert an arbitrary Bool term φ in the current scope:
    /// - propositionalize φ to CNF + root
    /// - add CNF clauses permanently
    /// - add guarded root clause (¬act ∨ root)
    pub fn assert_term_scoped(
        &mut self,
        ctx: &smt_core::Context,
        term: smt_core::BoolTerm,
        classifier: &dyn AtomClassifier,
    ) -> smt_core::Result<()> {
        let prop = propositionalize(ctx, term, classifier)?;

        // Merge atom tables (in a real engine, you'd maintain a global mapping term->var
        // and do incremental propositionalization; for now, assume fresh run or compatible vars).
        // For a minimal working system, just require all assertions go through a single global
        // propositionalizer and share term_to_var across assertions.

        // Add base CNF clauses
        for c in prop.cnf.clauses {
            self.sat.add_clause(c);
        }

        // Guard the root
        self.assert_lit_scoped(prop.root);
        Ok(())
    }

    /// Solve under the currently-active scope activations.
    pub fn solve(&mut self) -> SolveResult {
        // Assumptions = all active scope activations.
        let assumptions: Vec<Lit> = self.scopes.iter().map(|s| s.act).collect();

        // Reset search-level mirror
        self.sat_level_seen = self.sat.decision_level();
        self.sat.set_trail_head(0);

        // Seed assumptions at a fresh SAT decision level.
        if !assumptions.is_empty() {
            self.new_decision_level();
            for a in assumptions {
                if !self.sat.enqueue(a, None) {
                    return SolveResult::Unsat;
                }
            }
        }

        loop {
            if self.sat.propagate().is_err() {
                return SolveResult::Unsat;
            }
            self.sync_levels_with_sat();
            self.notify_theories_new_trail();

            // theory fixpoint
            if self.theory_fixpoint().is_err() {
                // a theory conflict lemma was added; continue, SAT will backjump/learn
                continue;
            }

            if self.sat.pick_branch_lit().is_none() {
                return SolveResult::Sat;
            }

            let d = self.sat.pick_branch_lit().unwrap();
            self.new_decision_level();
            let _ = self.sat.enqueue(d, None);
        }
    }

    // ---------------------------
    // CDCL(T) internal plumbing
    // ---------------------------

    fn new_decision_level(&mut self) {
        self.sat.new_decision_level();
        for th in self.theories.iter_mut() {
            th.push_level();
        }
        self.sat_level_seen = self.sat.decision_level();
    }

    fn sync_levels_with_sat(&mut self) {
        let cur = self.sat.decision_level();
        if cur > self.sat_level_seen {
            for _ in 0..(cur - self.sat_level_seen) {
                for th in self.theories.iter_mut() {
                    th.push_level();
                }
            }
        } else if cur < self.sat_level_seen {
            for th in self.theories.iter_mut() {
                th.pop_levels(self.sat_level_seen - cur);
            }
        }
        self.sat_level_seen = cur;
    }

    fn notify_theories_new_trail(&mut self) {
        let trail = self.sat.trail();
        let mut head = self.sat.trail_head();

        while head < trail.len() {
            let lit = trail[head];
            head += 1;

            if let Some(atom) = self.atoms.get(lit.var()) {
                let val = match self.sat.value_lit(lit) {
                    LBool::True => true,
                    LBool::False => false,
                    LBool::Undef => continue,
                };
                self.theories[atom.theory.0].on_atom_assigned(atom.term, val);
            }
        }

        self.sat.set_trail_head(head);
    }

    fn theory_fixpoint(&mut self) -> Result<(), ()> {
        loop {
            let mut any = false;

            for th in self.theories.iter_mut() {
                match th.propagate() {
                    Ok(props) => {
                        for p in props {
                            any = true;
                            // Permanent lemma (no activation needed: it is globally valid)
                            let lemma = implication_clause(&p.explain, p.implied);
                            let cidx = self.sat.add_clause_return_index(lemma);
                            let _ = self.sat.enqueue(p.implied, Some(cidx));
                        }
                    }
                    Err(conf) => {
                        any = true;
                        let lemma = conflict_clause(&conf.explain);
                        let _ = self.sat.add_clause_return_index(lemma);
                        return Err(());
                    }
                }
            }

            if !any {
                return Ok(());
            }

            if self.sat.propagate().is_err() {
                return Err(());
            }
            self.sync_levels_with_sat();
            self.notify_theories_new_trail();
        }
    }
}
```

### Key policy implemented

* **User assertions are guarded** with the current scope activation
* **Theory lemmas are permanent** (unguarded)
* Search-level rollback is handled by `push_level/pop_levels` mirrored from SAT

---

# 3) UNSAT core over user assertions (activation literals)

You can get a practical core with:

* return UNSAT under assumptions `act_0, act_1, ..., act_k`
* ask SAT kernel for an **assumption core** (subset of assumptions sufficient for UNSAT)

To support that cleanly, extend `SatKernel` with:

```rust
fn last_unsat_core(&self) -> Option<&[Lit]>;
```

and implement it in `ToyCdcl` using the “learned clause contains assumption vars” trick you already sketched earlier.

Then in the engine:

```rust
pub fn unsat_core_scopes(&self) -> Option<Vec<Lit>> {
    self.sat.last_unsat_core().map(|c| c.to_vec())
}
```

### Mapping that core to user assertions

Each `act` corresponds to a *scope*, not a single assertion. If you want “assertion-level cores”, you have two options:

1. **Scope-level core** (simple): core returns which scopes are involved.
2. **Assertion-level core** (common): each assertion gets its own activation literal, not just each scope.

I recommend assertion-level activations:

* On each `assert φ`, create a fresh `act_assert`
* Add `(¬act_scope ∨ ¬act_assert ∨ φ)`
* During solve assume both all active scope activations and all assertion activations in those scopes

Then UNSAT core gives you a subset of `act_assert` which directly identifies conflicting assertions.

---

# 4) Assertion-level activations (recommended)

Change `ScopeFrame` to store assertion activation lits:

```rust
struct ScopeFrame {
    act_scope: Lit,
    asserts: Vec<Lit>,  // activation lits per assertion in this scope
}
```

`push` creates `act_scope` and empty asserts.

`assert_term_scoped`:

* create `act_assert = Lit::pos(sat.fresh_var())`
* store it in the current scope frame
* assert guarded root clause:

`(¬act_scope ∨ ¬act_assert ∨ root)`

Implementation:

```rust
pub fn assert_root_scoped(&mut self, root: Lit) {
    let scope = self.scopes.last_mut().unwrap();
    let act_assert = Lit::pos(self.sat.fresh_var());
    scope.asserts.push(act_assert);

    // (¬act_scope ∨ ¬act_assert ∨ root)
    self.sat.add_clause(vec![scope.act_scope.not(), act_assert.not(), root]);
}
```

Solve assumptions are now:

* all `act_scope` for active scopes
* all `act_assert` for assertions in active scopes

```rust
let mut assumptions = Vec::new();
for scope in &self.scopes {
    assumptions.push(scope.act_scope);
    assumptions.extend_from_slice(&scope.asserts);
}
```

Now `last_unsat_core()` will typically return a subset of `act_assert` literals → **assertion-level UNSAT core**.

---

# What you get after this step

* Fully incremental SMT-LIB `push/pop`
* CDCL(T) correctness under SAT backjump/restarts
* Permanent theory lemmas (fast)
* Practical UNSAT cores tied to user assertions (great for debugging and for user experience)

---

If you say **yes** again, I’ll show the minimal changes to `ToyCdcl` to produce a **good assumption UNSAT core** (subset of assumption literals) in the CDCL kernel API (no DRAT needed), and then how to map those back to the exact asserted SMT terms (store `act_assert -> TermId`).
